Personal Reflection Agent

A full-stack generative AI application that helps users reflect on emotionally difficult experiences by transforming free-form personal input into a structured emotional reflection.

Built using Pydantic AI, with strict schema validation, fallback handling, and a polished end-to-end user experience.

ğŸ” What This Project Does

The Personal Reflection Agent allows users to describe a personal situation or experience they found emotionally challenging.
The system analyzes the input and returns a structured reflective response that is grounded strictly in the userâ€™s story.

Each response includes:

A detailed emotional summary

Detected emotions and emotional intensity

Key stressors involved in the situation

Cognitive patterns (e.g., rumination, self-doubt)

Reflection questions for self-awareness

Grounding suggestions appropriate to the situation

âš ï¸ This application is designed for reflection and emotional awareness, not therapy, diagnosis, or medical advice.

ğŸ§­ User Flow

User enters a description of a personal experience

User selects:

Support tone (gentle / neutral / direct)

Focus mode (emotion / thought / action)

The AI agent processes the input

A structured emotional reflection is returned in real time

ğŸ—ï¸ Technical Architecture
Backend

FastAPI â€“ API layer and request handling

Pydantic AI â€“ Agent orchestration and LLM interaction

Pydantic models â€“ Strict output schema validation

Fallback handling â€“ Ensures a safe, schema-valid response when input is unclear or the model fails

Retry & validation controls â€“ Improves reliability and stability

Frontend

Gradio â€“ Simple and responsive UI for user interaction

Model Access

Uses OpenRouter via an OpenAI-compatible API for LLM access

ğŸ›¡ï¸ Validation & Reliability

All AI outputs must conform to a predefined Pydantic schema

Minimum structure and content constraints are enforced

If the model output fails validation or the input is unclear, a fallback response is returned

This prevents crashes, retry loops, and invalid responses

ğŸŒ Live Deployment

ğŸ”— Live App:
https://personal-reflection-agent.onrender.com

Note: On Render Free tier, the app may take ~30â€“50 seconds to wake up after inactivity.

ğŸ“‚ Repository Structure
personal_reflection_agent/
â”œâ”€â”€ app.py              # FastAPI backend
â”œâ”€â”€ main.py             # ASGI entrypoint (Render)
â”œâ”€â”€ gradio_app.py       # Gradio UI
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ source/
â”‚   â”œâ”€â”€ agent/
â”‚   â”œâ”€â”€ graph/
â”‚   â”œâ”€â”€ nodes/
â”‚   â”œâ”€â”€ schema/
â”‚   â”œâ”€â”€ state/
â”‚   â””â”€â”€ utils/

â–¶ï¸ Run Locally
1ï¸âƒ£ Clone the repository
git clone https://github.com/siva05-orbit/personal_reflection_agent.git
cd personal_reflection_agent

2ï¸âƒ£ Create and activate virtual environment
python -m venv .venv
source .venv/bin/activate   # macOS / Linux
.venv\Scripts\activate      # Windows

3ï¸âƒ£ Install dependencies
pip install -r requirements.txt

4ï¸âƒ£ Set environment variables

Create a .env file:

OPENAI_API_KEY=your_api_key_here
OPENAI_BASE_URL=https://openrouter.ai/api/v1

5ï¸âƒ£ Run the app
uvicorn main:app --host 127.0.0.1 --port 8000


Open:

http://127.0.0.1:8000
